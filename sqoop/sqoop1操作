http://blog.csdn.net/dwld_3090271/article/details/50747639
http://www.micmiu.com/bigdata/sqoop/sqoop-setup-and-demo/

sqoop1导入数据到hdfs
sqoop import --connect jdbc:mysql://192.9.206.50:3306/sqoop --username root --password a  
--query 'select id,name,image_url,create_time,is_valid,del_flag,remark,sort from o_domain  where $CONDITIONS'
--split-by id   --target-dir /o_domain  --fields-terminated-by 't/005'


hive创建表
create table o_domain(id STRING,name STRING,image_url STRING,create_time STRING,is_valid STRING,del_flag STRING,remark STRING,sort STRING)
row format delimited
fields terminated by 't/005'
stored as TEXTFILE

在hive中加载sqoop1导入到hdfs的数据
load data inpath 'hdfs://mysql00:8020/o_domain/' into table o_domain
---------------------------------------------------------------------------
http://blog.csdn.net/z363115269/article/details/39048589

创建Hive表：
create table test_load(type STRING,num INT,time STRING)
partitioned by(name STRING)  //分区
row format delimited
fields terminated by ','  //以逗号分隔
stored as TEXTFILE

导入HDFS文件数据：
load data inpath 'hdfs://Master:9000/user/test/qar_test'
into table test_load
partition (name=‘MH');

set hive.cli.print.header=true; 开启查询列名及行转列显示
set hive.cli.print.row.to.vertical=true;
set hive.cli.print.row.to.vertical.num=1;


------------------------------------------------------
http://blog.csdn.net/myrainblues/article/details/43673129
create-hive-table
生成与关系数据库表的表结构对应的HIVE表
基础语句：
sqoop create-hive-table –connect jdbc:mysql://localhost:3306/hive -username root -password 123456 –table TBLS –hive-table h_tbls2

参数	说明
–hive-home <dir>	Hive的安装目录，可以通过该参数覆盖掉默认的hive目录
–hive-overwrite	覆盖掉在hive表中已经存在的数据
–create-hive-table	默认是false,如果目标表已经存在了，那么创建任务会失败
–hive-table	后面接要创建的hive表
–table	指定关系数据库表名
